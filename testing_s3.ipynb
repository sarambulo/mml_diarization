{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db12ae1e-6d12-41b6-8df0-7220ebd419ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Test access to s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_state": "idle",
   "id": "e7a7f13a-688b-4094-bf02-4f674d782697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket is accessible! Files:\n",
      "447\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "bucket_name = 'mmml-proj'\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "try:\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "    if 'Contents' in response:\n",
    "        print(\"Bucket is accessible! Files:\")\n",
    "        video_files = [obj['Key'] for obj in response['Contents'] if obj['Key'].endswith(\".mp4\")]\n",
    "        print(len(video_files))\n",
    "        # for obj in response['Contents']:\n",
    "            # print(obj['Key'])\n",
    "    else:\n",
    "        print(\"Bucket is accessible but empty.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error accessing bucket:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "execution_state": "idle",
   "id": "8b72927c-542a-4e48-a2e2-1cebcd40f554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2479\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "bucket_name = 'mmml-proj'\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "video_files = [\n",
    "    obj['Key'][:-4]\n",
    "    for page in paginator.paginate(Bucket=bucket_name)\n",
    "    if 'Contents' in page\n",
    "    for obj in page['Contents']\n",
    "    if obj['Key'].endswith(\".mp4\")\n",
    "]\n",
    "print(len(video_files))\n",
    "\n",
    "with open('uploaded_ids.txt', 'w') as f:\n",
    "    for file_id in video_files:\n",
    "        f.write(file_id + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "execution_state": "idle",
   "id": "e2091e8c-1bc2-4038-910b-6437987f3864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert numpy.ndarray to numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01ms3fs\u001b[39;00m  \u001b[38;5;66;03m# must be installed\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Credentials must be configured in ~/.aws/credentials or via env vars\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms3://mmml-proj/msdwild_boundingbox_labels/00547.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m df\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1968\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1966\u001b[0m         new_col_dict \u001b[38;5;241m=\u001b[39m col_dict\n\u001b[0;32m-> 1968\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_col_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[1;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/internals/construction.py:443\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Series\n\u001b[0;32m--> 443\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     missing \u001b[38;5;241m=\u001b[39m arrays\u001b[38;5;241m.\u001b[39misna()\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# GH10856\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# raise ValueError if only scalars in dict\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/series.py:490\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    487\u001b[0m name \u001b[38;5;241m=\u001b[39m ibase\u001b[38;5;241m.\u001b[39mmaybe_extract_name(name, data, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 490\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mensure_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dtype(dtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:7647\u001b[0m, in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   7645\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m MultiIndex\u001b[38;5;241m.\u001b[39mfrom_arrays(index_like)\n\u001b[1;32m   7646\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 7647\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtupleize_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   7648\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   7649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Index(index_like, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:565\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[1;32m    562\u001b[0m         data \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39m_dtype_obj)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex must be specified when data is not list-like\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/construction.py:654\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    651\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m _try_cast(data, dtype, copy)\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 654\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_platform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subarr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    656\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/dtypes/cast.py:138\u001b[0m, in \u001b[0;36mmaybe_convert_platform\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m _dtype_obj:\n\u001b[1;32m    137\u001b[0m     arr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, arr)\n\u001b[0;32m--> 138\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32mlib.pyx:2538\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert numpy.ndarray to numpy.ndarray"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import s3fs  # must be installed\n",
    "\n",
    "# Credentials must be configured in ~/.aws/credentials or via env vars\n",
    "df = pd.read_csv('s3://mmml-proj/msdwild_boundingbox_labels/00547.csv', storage_options={'anon': False})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "execution_state": "idle",
   "id": "663cbb18-7f2e-4cf6-9c6d-c0c959fc6e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '1957BP8E3ES6RQ81',\n",
       "  'HostId': 'ViPDKp0t0jsLW4VCPA/lNJF+GYhTEiIhqlW5lj5+vFGq8G7+wUxWgi4ozH1t+k7CvXQLtSIowMM=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'ViPDKp0t0jsLW4VCPA/lNJF+GYhTEiIhqlW5lj5+vFGq8G7+wUxWgi4ozH1t+k7CvXQLtSIowMM=',\n",
       "   'x-amz-request-id': '1957BP8E3ES6RQ81',\n",
       "   'date': 'Thu, 27 Mar 2025 21:30:39 GMT',\n",
       "   'last-modified': 'Wed, 26 Mar 2025 16:04:22 GMT',\n",
       "   'etag': '\"ca6d7ebd253ffde7f97e8681f2edbc90\"',\n",
       "   'x-amz-checksum-crc64nvme': '7m1vVD+dQFU=',\n",
       "   'x-amz-checksum-type': 'FULL_OBJECT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'accept-ranges': 'bytes',\n",
       "   'content-type': 'video/mp4',\n",
       "   'content-length': '8575352',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'AcceptRanges': 'bytes',\n",
       " 'LastModified': datetime.datetime(2025, 3, 26, 16, 4, 22, tzinfo=tzutc()),\n",
       " 'ContentLength': 8575352,\n",
       " 'ETag': '\"ca6d7ebd253ffde7f97e8681f2edbc90\"',\n",
       " 'ChecksumCRC64NVME': '7m1vVD+dQFU=',\n",
       " 'ChecksumType': 'FULL_OBJECT',\n",
       " 'ContentType': 'video/mp4',\n",
       " 'ServerSideEncryption': 'AES256',\n",
       " 'Metadata': {},\n",
       " 'Body': <botocore.response.StreamingBody at 0x7fd0a2714190>}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = s3.get_object(Bucket=bucket_name, Key=\"msdwild_boundingbox_labels/00547.mp4\")\n",
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43cac73-5976-43e6-8f26-6916fac4cc74",
   "metadata": {},
   "source": [
    "### Upload a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "execution_state": "idle",
   "id": "73bf37de-b7f8-4e04-9be0-5d06834edc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3.upload_file('local_file.csv', bucket, 'uploads/local_file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c28b1fb-0e71-4358-a689-41988060235d",
   "metadata": {},
   "source": [
    "### Download a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "execution_state": "idle",
   "id": "a58d994a-966d-4d6d-a000-e902285d85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3.download_file(bucket, 'path/in/s3/file.csv', 'local_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "execution_state": "idle",
   "id": "6d4feabd-7311-4e33-b101-31eec2a2be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(bucket_name, 'msdwild_boundingbox_labels/00547.mp4', '00547.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "execution_state": "idle",
   "id": "490d785a-2ea9-4a32-b52e-417cf3046b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(bucket_name, 'all.rttm', 'all.rttm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "execution_state": "idle",
   "id": "e2d73cd4-f800-458d-bc2b-df99b8ae3d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sagemaker-user'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "execution_state": "idle",
   "id": "b8dd9565-34d3-4885-b408-55323524befb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.2 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "jupyter-ai 2.29.1 requires faiss-cpu!=1.8.0.post0,<2.0.0,>=1.8.0, which is not installed.\n",
      "amazon-sagemaker-jupyter-ai-q-developer 1.0.16 requires numpy<=2.0.1, but you have numpy 2.0.2 which is incompatible.\n",
      "autogluon-core 1.2 requires scikit-learn<1.5.3,>=1.4.0, but you have scikit-learn 1.6.1 which is incompatible.\n",
      "autogluon-features 1.2 requires scikit-learn<1.5.3,>=1.4.0, but you have scikit-learn 1.6.1 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires nltk<3.9,>=3.4.5, but you have nltk 3.9.1 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires pytorch-metric-learning<2.4,>=1.3.0, but you have pytorch-metric-learning 2.8.1 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires scikit-learn<1.5.3,>=1.4.0, but you have scikit-learn 1.6.1 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires torch<2.6,>=2.2, but you have torch 2.6.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires torchmetrics<1.3.0,>=1.2.0, but you have torchmetrics 1.6.1 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires torchvision<0.21.0,>=0.16.0, but you have torchvision 0.21.0 which is incompatible.\n",
      "autogluon-timeseries 1.2 requires torch<2.6,>=2.2, but you have torch 2.6.0 which is incompatible.\n",
      "autogluon-tabular 1.2 requires scikit-learn<1.5.3,>=1.4.0, but you have scikit-learn 1.6.1 which is incompatible.\n",
      "catboost 1.2.7 requires numpy<2.0,>=1.16.0, but you have numpy 2.0.2 which is incompatible.\n",
      "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\n",
      "jupyter-scheduler 2.10.0 requires fsspec<=2024.10.0,>=2023.6.0, but you have fsspec 2025.2.0 which is incompatible.\n",
      "jupyter-scheduler 2.10.0 requires pytz<=2024.2,>=2023.3, but you have pytz 2025.1 which is incompatible.\n",
      "langchain-aws 0.2.10 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.0.2 which is incompatible.\n",
      "s3fs 2024.10.0 requires fsspec==2024.10.0.*, but you have fsspec 2025.2.0 which is incompatible.\n",
      "sagemaker 2.240.0 requires attrs<24,>=23.1.0, but you have attrs 25.1.0 which is incompatible.\n",
      "sagemaker 2.240.0 requires numpy<2.0,>=1.9.0, but you have numpy 2.0.2 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\n",
      "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "execution_state": "idle",
   "id": "b8b8ec01-7c0a-4d72-a72a-04e246e8925e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading msdwild_boundingbox_labels/00001.mp4\n",
      "{'fps': 25.0, 'duration': 24.28, 'sampling_rate': 44100.0}\n",
      "Building Video 00001 Chunks: 100%|████████████████| 5/5 [00:02<00:00,  2.08it/s]\n",
      "Loading msdwild_boundingbox_labels/00002.mp4\n",
      "{'fps': 25.0, 'duration': 65.68, 'sampling_rate': 44100.0}\n",
      "Building Video 00002 Chunks: 100%|██████████████| 14/14 [00:04<00:00,  2.98it/s]\n",
      "Loading msdwild_boundingbox_labels/00003.mp4\n",
      "{'fps': 25.0, 'duration': 62.48, 'sampling_rate': 44100.0}\n",
      "Building Video 00003 Chunks: 100%|██████████████| 13/13 [00:05<00:00,  2.38it/s]\n",
      "Loading msdwild_boundingbox_labels/00005.mp4\n",
      "{'fps': 25.0, 'duration': 25.56, 'sampling_rate': 44100.0}\n",
      "Building Video 00005 Chunks: 100%|████████████████| 6/6 [00:01<00:00,  3.06it/s]\n",
      "Loading msdwild_boundingbox_labels/00006.mp4\n",
      "{'fps': 25.0, 'duration': 408.36, 'sampling_rate': 44100.0}\n",
      "Building Video 00006 Chunks: 100%|██████████████| 60/60 [00:24<00:00,  2.46it/s]\n",
      "Loading msdwild_boundingbox_labels/00007.mp4\n",
      "{'fps': 25.0, 'duration': 170.36, 'sampling_rate': 48000.0}\n"
     ]
    }
   ],
   "source": [
    "!python preprocessing.py --data_dir s3://mmml-proj/msdwild_boundingbox_labels --rttm_path all.rttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "execution_state": "idle",
   "id": "edd078ae-6354-4459-b3db-3dd76f9e8f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://mmml-proj/preprocessed/00001\n",
      "s3://mmml-proj/preprocessed/00001/is_speaking.csv\n",
      "Saved Pairs Data to s3://mmml-proj/preprocessed/00001/pairs.csv\n",
      "Visual Pairs for Video 00001: 264it [00:15, 16.60it/s]\n"
     ]
    }
   ],
   "source": [
    "!python pairs/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "execution_state": "idle",
   "id": "ebeeca9c-65c5-47a0-9e26-90eaaafbbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3 = boto3.client('s3')\n",
    "import numpy as np\n",
    "import io\n",
    "def s3_load_numpy(bucket_name, file_key):\n",
    "    response = S3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "    data = response['Body'].read()\n",
    "    return np.load(io.BytesIO(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "execution_state": "idle",
   "id": "f984fffe-7104-4c09-9c07-efd6b49017aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_save_numpy(array, bucket_name, key):\n",
    "    byte_stream = io.BytesIO()\n",
    "    np.save(byte_stream, array, allow_pickle=False)\n",
    "    byte_stream.seek(0)\n",
    "    S3.upload_fileobj(byte_stream, bucket_name, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "execution_state": "idle",
   "id": "b3b146b8-f2b8-4b2c-8489-748d66dc3c59",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot load file containing pickled data when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ms3_load_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpreprocessed/00001/Chunk_1/face_1.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 7\u001b[0m, in \u001b[0;36ms3_load_numpy\u001b[0;34m(bucket_name, file_key)\u001b[0m\n\u001b[1;32m      5\u001b[0m response \u001b[38;5;241m=\u001b[39m S3\u001b[38;5;241m.\u001b[39mget_object(Bucket\u001b[38;5;241m=\u001b[39mbucket_name, Key\u001b[38;5;241m=\u001b[39mfile_key)\n\u001b[1;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numpy/lib/npyio.py:462\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot load file containing pickled data when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "s3_load_numpy(bucket_name, \"preprocessed/00001/Chunk_1/face_1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "execution_state": "idle",
   "id": "c0319828-6533-4161-945c-149f861a6701",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.random.random((5, 10))\n",
    "\n",
    "s3.upload_fileobj(io.BytesIO(np.ascontiguousarray(test)), bucket_name, \"test1.npy\")\n",
    "s3_save_numpy(test, bucket_name, \"test2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "execution_state": "idle",
   "id": "2fdc633f-24ff-479a-8221-ee5485c3e528",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot load file containing pickled data when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ms3_load_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest1.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 7\u001b[0m, in \u001b[0;36ms3_load_numpy\u001b[0;34m(bucket_name, file_key)\u001b[0m\n\u001b[1;32m      5\u001b[0m response \u001b[38;5;241m=\u001b[39m S3\u001b[38;5;241m.\u001b[39mget_object(Bucket\u001b[38;5;241m=\u001b[39mbucket_name, Key\u001b[38;5;241m=\u001b[39mfile_key)\n\u001b[1;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numpy/lib/npyio.py:462\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot load file containing pickled data when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "s3_load_numpy(bucket_name, \"test1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "execution_state": "idle",
   "id": "fdb6a943-f48b-4c8d-978d-f21cdaa17e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83789265, 0.04135803, 0.45794799, 0.92714576, 0.79517033,\n",
       "        0.1760513 , 0.42043891, 0.84819985, 0.97384609, 0.03722803],\n",
       "       [0.61801346, 0.70810853, 0.71825395, 0.69014013, 0.51471408,\n",
       "        0.30155016, 0.70601264, 0.7350254 , 0.28136025, 0.65643578],\n",
       "       [0.19264631, 0.51513671, 0.3845654 , 0.29506928, 0.41762364,\n",
       "        0.05271143, 0.57492549, 0.27031762, 0.22584251, 0.13021827],\n",
       "       [0.98516017, 0.45729878, 0.77027226, 0.88817958, 0.2706022 ,\n",
       "        0.3342182 , 0.06395108, 0.26593828, 0.11066054, 0.81881937],\n",
       "       [0.17398129, 0.44083448, 0.15302729, 0.87571018, 0.31875866,\n",
       "        0.95577013, 0.59600905, 0.73106122, 0.93873389, 0.1376843 ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_load_numpy(bucket_name, \"test2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441eaee6-d4bf-494d-8bf9-4b1024ae8b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
