{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_state": "idle",
   "id": "672648e8-a451-4de6-902d-c5dd69d73684",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datasets.MSDWild import MSDWildChunks\n",
    "from torch.utils.data import DataLoader\n",
    "from pairs.config import S3_BUCKET_NAME, S3_VIDEO_DIR\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_state": "idle",
   "id": "1fb562fe-8fe9-411e-90fe-25271652a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rttm_path = \"sample.rttm\"\n",
    "train_data_path = os.path.join(\"s3://\", S3_BUCKET_NAME, S3_VIDEO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "running",
   "id": "5a6614ea-a0cb-4dbe-992e-bb0775801815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Pair Metadata for Videos: 100%|██████████| 12/12 [00:01<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metadata for 4684 pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Triplet Files:  17%|█▋        | 2/12 [00:13<01:07,  6.76s/it]"
     ]
    }
   ],
   "source": [
    "dataset = MSDWildChunks(data_path=S3_VIDEO_DIR,\n",
    "                        data_bucket=S3_BUCKET_NAME,\n",
    "                        partition_path=train_rttm_path,\n",
    "                        subset=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "running",
   "id": "33fa3e0d-d103-455d-933b-e087bf119d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3fs -- 12/12 [03:04]\n",
    "# boto3 - 12/12 [02:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "running",
   "id": "3787d40d-957f-4dbd-8c61-d85490bc36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def collate_fn(batch):\n",
    "    # Extract each feature: do the zip thing\n",
    "    video_data, audio_data, is_speaking = list(zip(*batch))\n",
    "    # Padding: NOTE: Not necessary\n",
    "    # Stack:\n",
    "    video_data = torch.stack(video_data)\n",
    "    audio_data = torch.stack(audio_data)\n",
    "    is_speaking = torch.tensor(is_speaking)\n",
    "    # Return tuple((N, video_data, melspectrogram), (N, video_data, melspectrogram), (N, video_data, melspectrogram))\n",
    "    # (N, C, H, W), (N, Bands, T) x3 (ask Prachi)\n",
    "    batch_data = {\n",
    "        \"video_data\": video_data,\n",
    "        \"audio_data\": audio_data,\n",
    "        \"labels\": is_speaking,\n",
    "    }\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "running",
   "id": "77cc195c-e2ed-4e27-bd29-42ede7c578e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "running",
   "id": "3fd85022-d59e-466c-ac7e-24c4d42c0e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in loader:\n",
    "    print(i.keys())\n",
    "    print(i[\"video_data\"].shape)\n",
    "    print(i[\"audio_data\"].shape)\n",
    "    print(i[\"labels\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "running",
   "id": "53349fe9-86f4-4d65-8cbc-655c19ce748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import boto3\n",
    "import io\n",
    "\n",
    "# Save the entire model\n",
    "buffer = io.BytesIO()\n",
    "torch.save(loader, buffer)\n",
    "buffer.seek(0)\n",
    "\n",
    "# Upload to S3\n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.put_object(\n",
    "    Bucket=S3_BUCKET_NAME, \n",
    "    Key=\"loaders/sample_loader.pth\", \n",
    "    Body=buffer.getvalue()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "running",
   "id": "9d66102a-bf59-4c68-8a47-ea533eb20f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download from S3\n",
    "s3_client = boto3.client('s3')\n",
    "response = s3_client.get_object(Bucket=S3_BUCKET_NAME, Key=\"loaders/sample_loader.pth\")\n",
    "model_data = response['Body'].read()\n",
    "\n",
    "buffer = io.BytesIO(model_data)\n",
    "loader_3 = torch.load(buffer, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "running",
   "id": "0aea6d95-df82-4e87-8756-cb36d18be3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in loader_3:\n",
    "    print(i.keys())\n",
    "    print(i[\"video_data\"].shape)\n",
    "    print(i[\"audio_data\"].shape)\n",
    "    print(i[\"labels\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "34058423-78f2-46e4-8ad5-3bfbff5c6e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
