{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "execution_state": "idle",
   "id": "e0ef9cee-a96b-44b3-9074-258d10c589d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"datasets\")\n",
    "from datasets.MSDWildOptimized import LazyNPZDataset\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from models.VisualOnly import VisualOnlyModel\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from losses.DiarizationLoss import DiarizationLogitsLoss\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Subset\n",
    "from pairs.config import S3_BUCKET_NAME, S3_VIDEO_DIR\n",
    "import os\n",
    "from training.train_multimodal import *\n",
    "from training.visual_train import *\n",
    "from torchsummaryX import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "execution_state": "idle",
   "id": "5a39bc96-b77b-4b7d-b185-43f05e34f1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "NPZ_PATH = \"triplet_batches\"\n",
    "NPZ_BATCH_SIZE = 5000\n",
    "VISUAL_TYPE = \"face\"  # lip or face\n",
    "\n",
    "MODEL_BATCH_SIZE = 64\n",
    "\n",
    "CHECKPOINT_PATH = \"model_checkpoints\"\n",
    "\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "execution_state": "idle",
   "id": "74304c38-314b-40ce-ad6d-646fca3b91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LazyNPZDataset(\n",
    "    npz_dir=NPZ_PATH,\n",
    "    batch_size=NPZ_BATCH_SIZE,\n",
    "    end=65,\n",
    "    bucket=S3_BUCKET_NAME,\n",
    "    shuffle_within_file=True,\n",
    "    visual_type=VISUAL_TYPE,\n",
    ")\n",
    "\n",
    "val_dataset = LazyNPZDataset(\n",
    "    npz_dir=NPZ_PATH,\n",
    "    batch_size=NPZ_BATCH_SIZE,\n",
    "    start=66,\n",
    "    bucket=S3_BUCKET_NAME,\n",
    "    shuffle_within_file=True,\n",
    "    visual_type=VISUAL_TYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "execution_state": "idle",
   "id": "a2553693-e78e-4cd8-bea0-baaeaf32154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=MODEL_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=train_dataset.collate_fn,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=MODEL_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=val_dataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "execution_state": "idle",
   "id": "2723a45d-daac-46d4-bdef-e3ceb3f228c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5079 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# print(\"Visual Data Shape:\", batch[0].shape)\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# print(\"Audio Data Shape:\", batch[1].shape)\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# print(\"Labels:\", batch[2])\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# break\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot through \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m batches\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/mml_diarization/datasets/MSDWildOptimized.py:91\u001b[0m, in \u001b[0;36mLazyNPZDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Load file if not already cached\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_idx \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_file_index:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Apply in-file shuffle if requested\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshuffle_within_file:\n",
      "File \u001b[0;32m~/mml_diarization/datasets/MSDWildOptimized.py:104\u001b[0m, in \u001b[0;36mLazyNPZDataset._load_file\u001b[0;34m(self, file_idx)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_idx: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Load and cache the .npz file\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_npz_from_s3\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnpz_file_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfile_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisual_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisual_type\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_file_index \u001b[38;5;241m=\u001b[39m file_idx\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshuffle_within_file:\n",
      "File \u001b[0;32m~/mml_diarization/datasets/MSDWildOptimized.py:30\u001b[0m, in \u001b[0;36mload_npz_from_s3\u001b[0;34m(bucket, key, visual_type)\u001b[0m\n\u001b[1;32m     28\u001b[0m s3 \u001b[38;5;241m=\u001b[39m boto3\u001b[38;5;241m.\u001b[39mclient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m response \u001b[38;5;241m=\u001b[39m s3\u001b[38;5;241m.\u001b[39mget_object(Bucket\u001b[38;5;241m=\u001b[39mbucket, Key\u001b[38;5;241m=\u001b[39mkey)\n\u001b[0;32m---> 30\u001b[0m npz_bytes \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBody\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     31\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(npz_bytes, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     33\u001b[0m result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisual_data\u001b[39m\u001b[38;5;124m\"\u001b[39m: data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvisual_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_data\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_data\u001b[39m\u001b[38;5;124m\"\u001b[39m: data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_data\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     37\u001b[0m }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/botocore/response.py:99\u001b[0m, in \u001b[0;36mStreamingBody.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read at most amt bytes from the stream.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03mIf the amt argument is omitted, read all data.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m URLLib3ReadTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# TODO: the url will be None as urllib3 isn't setting it yet\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(endpoint_url\u001b[38;5;241m=\u001b[39me\u001b[38;5;241m.\u001b[39murl, error\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/response.py:955\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 955\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    876\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 879\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:489\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 489\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead:\n\u001b[1;32m    491\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:638\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[1;32m    632\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[1;32m    640\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for batch in tqdm(train_loader):\n",
    "    # print(\"Visual Data Shape:\", batch[0].shape)\n",
    "    # print(\"Audio Data Shape:\", batch[1].shape)\n",
    "    # print(\"Labels:\", batch[2])\n",
    "    # break\n",
    "    num += 1\n",
    "print(f\"got through {num} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "execution_state": "idle",
   "id": "c919c916-4f1b-4077-a929-cef906e7f6d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m VISUAL_TYPE \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     visual_model \u001b[38;5;241m=\u001b[39m \u001b[43mVisualOnlyModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpretrained/visual_encoder.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m VISUAL_TYPE \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      4\u001b[0m     visual_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m#TODO: add ResNet Model\u001b[39;00m\n",
      "File \u001b[0;32m~/mml_diarization/models/VisualOnly.py:104\u001b[0m, in \u001b[0;36mVisualOnlyModel.__init__\u001b[0;34m(self, embedding_dims, weights_path)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(embedding_dims, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_path:\n\u001b[0;32m--> 104\u001b[0m    checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m    model_state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    106\u001b[0m    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_state_dict(model_state_dict)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:1471\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1469\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1470\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1471\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1479\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:1964\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[1;32m   1963\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1964\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1965\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:1928\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1928\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:1900\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1895\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1898\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1899\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1900\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1901\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1902\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1903\u001b[0m )\n\u001b[1;32m   1905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1906\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:693\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 693\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:631\u001b[0m, in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    629\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[0;32m--> 631\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:600\u001b[0m, in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    598\u001b[0m     device_index \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_available\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    601\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.is_available() is False. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m     )\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_count\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    608\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m device_module\u001b[38;5;241m.\u001b[39mdevice_count()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "if VISUAL_TYPE == \"face\":\n",
    "    visual_model = VisualOnlyModel(\n",
    "        embedding_dims=1024, weights_path=\"pretrained/visual_encoder.pth\"\n",
    "    )\n",
    "elif VISUAL_TYPE == \"lip\":\n",
    "    visual_model = None  # TODO: add ResNet Model\n",
    "else:\n",
    "    raise ValueError(\"Invalid visual type: \" + VISUAL_TYPE)\n",
    "\n",
    "audio_model = None  # TODO: add audio model\n",
    "\n",
    "model = None  # TODO: create multimodal model\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = DiarizationLogitsLoss(0.3, 0.7)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.8, patience=8\n",
    ")\n",
    "\n",
    "start_epoch = 0\n",
    "final_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "execution_state": "idle",
   "id": "db2030a5-fd12-415a-a3e3-54670d5dfb23",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m best_valid_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mstart_epoch\u001b[49m, final_epoch):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, final_epoch))\n\u001b[1;32m      5\u001b[0m     curr_lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(scheduler\u001b[38;5;241m.\u001b[39mget_last_lr()[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start_epoch' is not defined"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "best_valid_acc = 0\n",
    "for epoch in range(start_epoch, final_epoch):\n",
    "    print(\"\\nEpoch {}/{}\".format(epoch + 1, final_epoch))\n",
    "    curr_lr = float(scheduler.get_last_lr()[0])\n",
    "    metrics.update({\"lr\": curr_lr})\n",
    "    train_acc, train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    print(\n",
    "        \"\\nEpoch {}/{}: \\nTrain Cls. Acc {:.04f}%\\t Train Cls. Loss {:.04f}\\t Learning Rate {:.04f}\".format(\n",
    "            epoch + 1, final_epoch, train_acc, train_loss, curr_lr\n",
    "        )\n",
    "    )\n",
    "    metrics.update({\"train_cls_acc\": train_acc, \"train_loss\": train_loss})\n",
    "    valid_acc, valid_loss = evaluate_epoch(model, val_loader, criterion)\n",
    "    print(\"Val Cls. Acc {:.04f}%\\t Val Cls. Loss {:.04f}\".format(valid_acc, valid_loss))\n",
    "    metrics.update({\"valid_cls_acc\": valid_acc, \"valid_loss\": valid_loss})\n",
    "    if epoch % 5 == 4:\n",
    "        epoch_ckpt_path = Path(CHECKPOINT_PATH, f\"epoch_{epoch+1}.pth\")\n",
    "        save_model(model, metrics, epoch, epoch_ckpt_path)\n",
    "    if valid_acc >= best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        save_model(model, metrics, epoch, Path(CHECKPOINT_PATH, \"best_visual.pth\"))\n",
    "    if scheduler is not None:\n",
    "        scheduler.step(valid_loss)\n",
    "save_model(model, metrics, epoch, Path(CHECKPOINT_PATH, \"last_visual.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "execution_state": "idle",
   "id": "b6e9e601-c034-4e45-9ed9-abe40a3f6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_size = len(full_dataset)\n",
    "# indices = list(range(dataset_size))\n",
    "# random.shuffle(indices)\n",
    "# split = int(0.8 * dataset_size)\n",
    "# train_indices = indices[:split]\n",
    "# val_indices   = indices[split:]\n",
    "# train_subset = Subset(full_dataset, train_indices)\n",
    "# val_subset   = Subset(full_dataset, val_indices)\n",
    "# train_loader = DataLoader(\n",
    "#     train_subset,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=True,\n",
    "#     collate_fn=full_dataset.build_batch\n",
    "# )\n",
    "# val_loader = DataLoader(\n",
    "#     val_subset,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=False,\n",
    "#     collate_fn=full_dataset.build_batch\n",
    "# )\n",
    "# print(f\"Train size: {len(train_subset)}   Val size: {len(val_subset)}\")\n",
    "# model = VisualOnlyModel(embedding_dims=512, num_classes=2)\n",
    "# model = model.float().to(DEVICE)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "# criterion = DiarizationLogitsLoss(0.3, 0.7)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, patience=8)\n",
    "# start_epoch = 0\n",
    "# final_epoch = 100\n",
    "# metrics = {}\n",
    "# best_valid_acc = 0\n",
    "# for epoch in range(start_epoch, final_epoch):\n",
    "#         print(\"\\nEpoch {}/{}\".format(epoch+1, final_epoch))\n",
    "#         curr_lr = float(scheduler.get_last_lr()[0])\n",
    "#         metrics.update({'lr': curr_lr})\n",
    "#         train_acc, train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "#         print(\"\\nEpoch {}/{}: \\nTrain Cls. Acc {:.04f}%\\t Train Cls. Loss {:.04f}\\t Learning Rate {:.04f}\".format(epoch + 1, final_epoch, train_acc, train_loss, curr_lr))\n",
    "#         metrics.update({'train_cls_acc': train_acc, 'train_loss': train_loss})\n",
    "#         valid_acc, valid_loss = evaluate_epoch(model, val_loader, criterion)\n",
    "#         print(\"Val Cls. Acc {:.04f}%\\t Val Cls. Loss {:.04f}\".format(valid_acc, valid_loss))\n",
    "#         metrics.update({'valid_cls_acc': valid_acc, 'valid_loss': valid_loss})\n",
    "#         if epoch%5==4:\n",
    "#             epoch_ckpt_path = Path(CHECKPOINT_PATH, f\"epoch_{epoch+1}.pth\")\n",
    "#             save_model(model, metrics, epoch, epoch_ckpt_path)\n",
    "#         if valid_acc >= best_valid_acc:\n",
    "#             best_valid_acc = valid_acc\n",
    "#             save_model(model, metrics, epoch, Path(CHECKPOINT_PATH, 'best_visual.pth'))\n",
    "#         if scheduler is not None:\n",
    "#             scheduler.step(valid_loss)\n",
    "# save_model(model, metrics, epoch, Path(CHECKPOINT_PATH, 'last_visual.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "execution_state": "idle",
   "id": "9f67f4b6-c2ff-4e88-b455-76efdf4ba8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "training: loss: 0.2320, acc: 0.9627\n",
      "val: loss: 0.1941, acc: 0.9675\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_1.pth\n",
      "\n",
      "Epoch 2/100\n",
      "training: loss: 0.1196, acc: 0.9684\n",
      "val: loss: 0.1182, acc: 0.9675\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_2.pth\n",
      "\n",
      "Epoch 3/100\n",
      "training: loss: 0.1006, acc: 0.9669\n",
      "val: loss: 0.1094, acc: 0.9675\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_3.pth\n",
      "\n",
      "Epoch 4/100\n",
      "training: loss: 0.0929, acc: 0.9660\n",
      "val: loss: 0.1033, acc: 0.9675\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_4.pth\n",
      "\n",
      "Epoch 5/100\n",
      "training: loss: 0.0866, acc: 0.9648\n",
      "val: loss: 0.1046, acc: 0.9675\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_5.pth\n",
      "\n",
      "Epoch 6/100\n",
      "Update Schedule to visual_last\n",
      "training: loss: 0.0816, acc: 0.9678\n",
      "val: loss: 0.0829, acc: 0.9675\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_6.pth\n",
      "\n",
      "Epoch 7/100\n",
      "training: loss: 0.0807, acc: 0.9675\n",
      "val: loss: 0.0823, acc: 0.9675\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_7.pth\n",
      "\n",
      "Epoch 8/100\n",
      "training: loss: 0.0800, acc: 0.9677\n",
      "val: loss: 0.0817, acc: 0.9675\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_8.pth\n",
      "\n",
      "Epoch 9/100\n",
      "training: loss: 0.0785, acc: 0.9672\n",
      "val: loss: 0.0811, acc: 0.9675\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_9.pth\n",
      "\n",
      "Epoch 10/100\n",
      "training: loss: 0.0776, acc: 0.9671\n",
      "val: loss: 0.0811, acc: 0.9675\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_10.pth\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_10.pth\n",
      "\n",
      "Epoch 11/100\n",
      "Update Schedule to all\n",
      "training: loss: 0.0771, acc: 0.9675\n",
      "val: loss: 0.0804, acc: 0.9675\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_11.pth\n",
      "\n",
      "Epoch 12/100\n",
      "training: loss: 0.0760, acc: 0.9672\n",
      "val: loss: 0.0795, acc: 0.9675\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_12.pth\n",
      "\n",
      "Epoch 13/100\n",
      "training: loss: 0.0749, acc: 0.9677\n",
      "val: loss: 0.0797, acc: 0.9675\n",
      "\n",
      "Epoch 14/100\n",
      "training: loss: 0.0755, acc: 0.9669\n",
      "val: loss: 0.0792, acc: 0.9675\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_14.pth\n",
      "\n",
      "Epoch 15/100\n",
      "training: loss: 0.0752, acc: 0.9669\n",
      "val: loss: 0.0780, acc: 0.9675\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_15.pth\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_15.pth\n",
      "\n",
      "Epoch 16/100\n",
      "training: loss: 0.0741, acc: 0.9670\n",
      "val: loss: 0.0772, acc: 0.9675\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_16.pth\n",
      "\n",
      "Epoch 17/100\n",
      "training: loss: 0.0732, acc: 0.9698\n",
      "val: loss: 0.0769, acc: 0.9771\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_17.pth\n",
      "\n",
      "Epoch 18/100\n",
      "training: loss: 0.0725, acc: 0.9689\n",
      "val: loss: 0.0758, acc: 0.9767\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_18.pth\n",
      "\n",
      "Epoch 19/100\n",
      "training: loss: 0.0718, acc: 0.9697\n",
      "val: loss: 0.0744, acc: 0.9778\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_19.pth\n",
      "\n",
      "Epoch 20/100\n",
      "training: loss: 0.0718, acc: 0.9693\n",
      "val: loss: 0.0739, acc: 0.9782\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_20.pth\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_20.pth\n",
      "\n",
      "Epoch 21/100\n",
      "training: loss: 0.0705, acc: 0.9722\n",
      "val: loss: 0.0731, acc: 0.9774\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_21.pth\n",
      "\n",
      "Epoch 22/100\n",
      "training: loss: 0.0710, acc: 0.9711\n",
      "val: loss: 0.0723, acc: 0.9782\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_22.pth\n",
      "\n",
      "Epoch 23/100\n",
      "training: loss: 0.0697, acc: 0.9733\n",
      "val: loss: 0.0727, acc: 0.9774\n",
      "\n",
      "Epoch 24/100\n",
      "training: loss: 0.0703, acc: 0.9729\n",
      "val: loss: 0.0723, acc: 0.9767\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_24.pth\n",
      "\n",
      "Epoch 25/100\n",
      "training: loss: 0.0691, acc: 0.9717\n",
      "val: loss: 0.0711, acc: 0.9782\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_25.pth\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_25.pth\n",
      "\n",
      "Epoch 26/100\n",
      "training: loss: 0.0687, acc: 0.9729\n",
      "val: loss: 0.0713, acc: 0.9782\n",
      "\n",
      "Epoch 27/100\n",
      "training: loss: 0.0684, acc: 0.9736\n",
      "val: loss: 0.0715, acc: 0.9778\n",
      "\n",
      "Epoch 28/100\n",
      "training: loss: 0.0684, acc: 0.9732\n",
      "val: loss: 0.0706, acc: 0.9782\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_28.pth\n",
      "\n",
      "Epoch 29/100\n",
      "training: loss: 0.0671, acc: 0.9746\n",
      "val: loss: 0.0702, acc: 0.9794\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_29.pth\n",
      "\n",
      "Epoch 30/100\n",
      "training: loss: 0.0675, acc: 0.9737\n",
      "val: loss: 0.0701, acc: 0.9790\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_30.pth\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_30.pth\n",
      "\n",
      "Epoch 31/100\n",
      "training: loss: 0.0669, acc: 0.9748\n",
      "val: loss: 0.0717, acc: 0.9778\n",
      "\n",
      "Epoch 32/100\n",
      "training: loss: 0.0660, acc: 0.9734\n",
      "val: loss: 0.0702, acc: 0.9771\n",
      "\n",
      "Epoch 33/100\n",
      "training: loss: 0.0675, acc: 0.9742\n",
      "val: loss: 0.0713, acc: 0.9759\n",
      "\n",
      "Epoch 34/100\n",
      "training: loss: 0.0665, acc: 0.9735\n",
      "val: loss: 0.0700, acc: 0.9774\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_34.pth\n",
      "\n",
      "Epoch 35/100\n",
      "training: loss: 0.0653, acc: 0.9758\n",
      "val: loss: 0.0690, acc: 0.9786\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_35.pth\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_35.pth\n",
      "\n",
      "Epoch 36/100\n",
      "training: loss: 0.0653, acc: 0.9750\n",
      "val: loss: 0.0691, acc: 0.9786\n",
      "\n",
      "Epoch 37/100\n",
      "training: loss: 0.0647, acc: 0.9759\n",
      "val: loss: 0.0687, acc: 0.9778\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_37.pth\n",
      "\n",
      "Epoch 38/100\n",
      "training: loss: 0.0649, acc: 0.9746\n",
      "val: loss: 0.0698, acc: 0.9782\n",
      "\n",
      "Epoch 39/100\n",
      "training: loss: 0.0642, acc: 0.9755\n",
      "val: loss: 0.0705, acc: 0.9797\n",
      "\n",
      "Epoch 40/100\n",
      "training: loss: 0.0640, acc: 0.9769\n",
      "val: loss: 0.0705, acc: 0.9725\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_40.pth\n",
      "\n",
      "Epoch 41/100\n",
      "training: loss: 0.0635, acc: 0.9750\n",
      "val: loss: 0.0689, acc: 0.9786\n",
      "\n",
      "Epoch 42/100\n",
      "training: loss: 0.0632, acc: 0.9769\n",
      "val: loss: 0.0674, acc: 0.9794\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_42.pth\n",
      "\n",
      "Epoch 43/100\n",
      "training: loss: 0.0618, acc: 0.9775\n",
      "val: loss: 0.0668, acc: 0.9794\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_43.pth\n",
      "\n",
      "Epoch 44/100\n",
      "training: loss: 0.0616, acc: 0.9772\n",
      "val: loss: 0.0679, acc: 0.9797\n",
      "\n",
      "Epoch 45/100\n",
      "training: loss: 0.0627, acc: 0.9747\n",
      "val: loss: 0.0683, acc: 0.9778\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_45.pth\n",
      "\n",
      "Epoch 46/100\n",
      "training: loss: 0.0614, acc: 0.9773\n",
      "val: loss: 0.0677, acc: 0.9774\n",
      "\n",
      "Epoch 47/100\n",
      "training: loss: 0.0620, acc: 0.9771\n",
      "val: loss: 0.0681, acc: 0.9778\n",
      "\n",
      "Epoch 48/100\n",
      "training: loss: 0.0614, acc: 0.9772\n",
      "val: loss: 0.0725, acc: 0.9717\n",
      "\n",
      "Epoch 49/100\n",
      "training: loss: 0.0616, acc: 0.9771\n",
      "val: loss: 0.0663, acc: 0.9790\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_49.pth\n",
      "\n",
      "Epoch 50/100\n",
      "training: loss: 0.0608, acc: 0.9773\n",
      "val: loss: 0.0689, acc: 0.9744\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_50.pth\n",
      "\n",
      "Epoch 51/100\n",
      "training: loss: 0.0605, acc: 0.9775\n",
      "val: loss: 0.0700, acc: 0.9725\n",
      "\n",
      "Epoch 52/100\n",
      "training: loss: 0.0603, acc: 0.9781\n",
      "val: loss: 0.0666, acc: 0.9790\n",
      "\n",
      "Epoch 53/100\n",
      "training: loss: 0.0604, acc: 0.9774\n",
      "val: loss: 0.0694, acc: 0.9721\n",
      "\n",
      "Epoch 54/100\n",
      "training: loss: 0.0599, acc: 0.9781\n",
      "val: loss: 0.0674, acc: 0.9782\n",
      "\n",
      "Epoch 55/100\n",
      "training: loss: 0.0594, acc: 0.9777\n",
      "val: loss: 0.0690, acc: 0.9736\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_55.pth\n",
      "\n",
      "Epoch 56/100\n",
      "training: loss: 0.0587, acc: 0.9777\n",
      "val: loss: 0.0674, acc: 0.9767\n",
      "\n",
      "Epoch 57/100\n",
      "training: loss: 0.0589, acc: 0.9796\n",
      "val: loss: 0.0687, acc: 0.9729\n",
      "\n",
      "Epoch 58/100\n",
      "training: loss: 0.0578, acc: 0.9793\n",
      "val: loss: 0.0670, acc: 0.9774\n",
      "\n",
      "Epoch 59/100\n",
      "training: loss: 0.0578, acc: 0.9787\n",
      "val: loss: 0.0652, acc: 0.9801\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_59.pth\n",
      "\n",
      "Epoch 60/100\n",
      "training: loss: 0.0574, acc: 0.9807\n",
      "val: loss: 0.0660, acc: 0.9786\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_60.pth\n",
      "\n",
      "Epoch 61/100\n",
      "training: loss: 0.0573, acc: 0.9793\n",
      "val: loss: 0.0668, acc: 0.9771\n",
      "\n",
      "Epoch 62/100\n",
      "training: loss: 0.0570, acc: 0.9804\n",
      "val: loss: 0.0693, acc: 0.9778\n",
      "\n",
      "Epoch 63/100\n",
      "training: loss: 0.0569, acc: 0.9789\n",
      "val: loss: 0.0675, acc: 0.9767\n",
      "\n",
      "Epoch 64/100\n",
      "training: loss: 0.0563, acc: 0.9815\n",
      "val: loss: 0.0647, acc: 0.9774\n",
      "Saving to multimodal_concat_512_checkpoints/best_model_64.pth\n",
      "\n",
      "Epoch 65/100\n",
      "training: loss: 0.0554, acc: 0.9817\n",
      "val: loss: 0.0648, acc: 0.9782\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_65.pth\n",
      "\n",
      "Epoch 66/100\n",
      "training: loss: 0.0560, acc: 0.9811\n",
      "val: loss: 0.0688, acc: 0.9744\n",
      "\n",
      "Epoch 67/100\n",
      "training: loss: 0.0550, acc: 0.9823\n",
      "val: loss: 0.0653, acc: 0.9778\n",
      "\n",
      "Epoch 68/100\n",
      "training: loss: 0.0550, acc: 0.9816\n",
      "val: loss: 0.0659, acc: 0.9767\n",
      "\n",
      "Epoch 69/100\n",
      "training: loss: 0.0544, acc: 0.9809\n",
      "val: loss: 0.0656, acc: 0.9782\n",
      "\n",
      "Epoch 70/100\n",
      "training: loss: 0.0537, acc: 0.9824\n",
      "val: loss: 0.0661, acc: 0.9748\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_70.pth\n",
      "\n",
      "Epoch 71/100\n",
      "training: loss: 0.0536, acc: 0.9816\n",
      "val: loss: 0.0674, acc: 0.9759\n",
      "\n",
      "Epoch 72/100\n",
      "training: loss: 0.0532, acc: 0.9820\n",
      "val: loss: 0.0657, acc: 0.9755\n",
      "\n",
      "Epoch 73/100\n",
      "training: loss: 0.0524, acc: 0.9841\n",
      "val: loss: 0.0728, acc: 0.9717\n",
      "\n",
      "Epoch 74/100\n",
      "training: loss: 0.0539, acc: 0.9826\n",
      "val: loss: 0.0654, acc: 0.9763\n",
      "\n",
      "Epoch 75/100\n",
      "training: loss: 0.0529, acc: 0.9828\n",
      "val: loss: 0.0681, acc: 0.9721\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_75.pth\n",
      "\n",
      "Epoch 76/100\n",
      "training: loss: 0.0523, acc: 0.9823\n",
      "val: loss: 0.0670, acc: 0.9771\n",
      "\n",
      "Epoch 77/100\n",
      "training: loss: 0.0516, acc: 0.9840\n",
      "val: loss: 0.0663, acc: 0.9744\n",
      "\n",
      "Epoch 78/100\n",
      "training: loss: 0.0511, acc: 0.9840\n",
      "val: loss: 0.0692, acc: 0.9748\n",
      "\n",
      "Epoch 79/100\n",
      "training: loss: 0.0527, acc: 0.9833\n",
      "val: loss: 0.0673, acc: 0.9748\n",
      "\n",
      "Epoch 80/100\n",
      "training: loss: 0.0510, acc: 0.9834\n",
      "val: loss: 0.0673, acc: 0.9748\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_80.pth\n",
      "\n",
      "Epoch 81/100\n",
      "training: loss: 0.0507, acc: 0.9843\n",
      "val: loss: 0.0673, acc: 0.9763\n",
      "\n",
      "Epoch 82/100\n",
      "training: loss: 0.0498, acc: 0.9850\n",
      "val: loss: 0.0720, acc: 0.9729\n",
      "\n",
      "Epoch 83/100\n",
      "training: loss: 0.0486, acc: 0.9860\n",
      "val: loss: 0.0698, acc: 0.9752\n",
      "\n",
      "Epoch 84/100\n",
      "training: loss: 0.0490, acc: 0.9845\n",
      "val: loss: 0.0715, acc: 0.9725\n",
      "\n",
      "Epoch 85/100\n",
      "training: loss: 0.0491, acc: 0.9852\n",
      "val: loss: 0.0711, acc: 0.9759\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_85.pth\n",
      "\n",
      "Epoch 86/100\n",
      "training: loss: 0.0486, acc: 0.9846\n",
      "val: loss: 0.0711, acc: 0.9732\n",
      "\n",
      "Epoch 87/100\n",
      "training: loss: 0.0479, acc: 0.9859\n",
      "val: loss: 0.0713, acc: 0.9748\n",
      "\n",
      "Epoch 88/100\n",
      "training: loss: 0.0477, acc: 0.9880\n",
      "val: loss: 0.0787, acc: 0.9786\n",
      "\n",
      "Epoch 89/100\n",
      "training: loss: 0.0481, acc: 0.9863\n",
      "val: loss: 0.0709, acc: 0.9752\n",
      "\n",
      "Epoch 90/100\n",
      "training: loss: 0.0475, acc: 0.9864\n",
      "val: loss: 0.0703, acc: 0.9744\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_90.pth\n",
      "\n",
      "Epoch 91/100\n",
      "training: loss: 0.0463, acc: 0.9873\n",
      "val: loss: 0.0756, acc: 0.9748\n",
      "\n",
      "Epoch 92/100\n",
      "training: loss: 0.0478, acc: 0.9856\n",
      "val: loss: 0.0790, acc: 0.9675\n",
      "\n",
      "Epoch 93/100\n",
      "training: loss: 0.0468, acc: 0.9867\n",
      "val: loss: 0.0724, acc: 0.9729\n",
      "\n",
      "Epoch 94/100\n",
      "training: loss: 0.0448, acc: 0.9879\n",
      "val: loss: 0.0736, acc: 0.9736\n",
      "\n",
      "Epoch 95/100\n",
      "training: loss: 0.0450, acc: 0.9889\n",
      "val: loss: 0.0754, acc: 0.9729\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_95.pth\n",
      "\n",
      "Epoch 96/100\n",
      "training: loss: 0.0455, acc: 0.9875\n",
      "val: loss: 0.0748, acc: 0.9729\n",
      "\n",
      "Epoch 97/100\n",
      "training: loss: 0.0458, acc: 0.9875\n",
      "val: loss: 0.0780, acc: 0.9717\n",
      "\n",
      "Epoch 98/100\n",
      "training: loss: 0.0426, acc: 0.9898\n",
      "val: loss: 0.0757, acc: 0.9729\n",
      "\n",
      "Epoch 99/100\n",
      "training: loss: 0.0434, acc: 0.9896\n",
      "val: loss: 0.0776, acc: 0.9721\n",
      "\n",
      "Epoch 100/100\n",
      "training: loss: 0.0441, acc: 0.9890\n",
      "val: loss: 0.0736, acc: 0.9706\n",
      "Saving to multimodal_concat_512_checkpoints/epoch_multimodal_100.pth\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "##LOAD CHECKPOINTS\n",
    "audio_model = CompactAudioEmbedding(input_dim=40, embedding_dim=512, dropout_rate=0.3)\n",
    "old_audio_dict = torch.load(\"12.pth\", map_location=DEVICE)\n",
    "\n",
    "new_audio_state_dict = {}\n",
    "for key, value in old_audio_dict.items():\n",
    "    if key.startswith(\"classifier\"):\n",
    "        continue\n",
    "    new_key = key.replace(\"encoder.\", \"\")\n",
    "    new_audio_state_dict[new_key] = value\n",
    "\n",
    "audio_model.load_state_dict(new_audio_state_dict)\n",
    "\n",
    "visual_model = ResNet34(embedding_dims=512)\n",
    "\n",
    "vid_state_dict = torch.load(\"model_checkpoints/epoch_55.pth\", map_location=DEVICE)[\n",
    "    \"model_state_dict\"\n",
    "]\n",
    "\n",
    "new_vid_state_dict = {}\n",
    "for key, value in vid_state_dict.items():\n",
    "    if key.startswith(\"visual_encoder.\"):\n",
    "        new_key = key.replace(\"visual_encoder.\", \"\")\n",
    "        new_vid_state_dict[new_key] = value\n",
    "    elif key.startswith(\"classifier\"):\n",
    "        continue\n",
    "    else:\n",
    "        new_vid_state_dict[key] = value\n",
    "visual_model.load_state_dict(new_vid_state_dict)\n",
    "\n",
    "fusion_model = ConcatenationFusionModel(\n",
    "    audio_model=audio_model,\n",
    "    visual_model=visual_model,\n",
    "    fusion_dim=512,\n",
    "    embedding_dim=512,\n",
    "    fusion_type=\"additive\",\n",
    ").to(DEVICE)\n",
    "\n",
    "# train_rttm_path = \"data_sample/all.rttm\"\n",
    "# train_data_path = \"preprocessed\"\n",
    "\n",
    "# train_dataset_full = MSDWildChunks(\n",
    "#     data_path=train_data_path, rttm_path=train_rttm_path, subset=0.8\n",
    "# )\n",
    "\n",
    "# # split few_train into train + val\n",
    "train_size = int(0.8 * full_dataset.length)\n",
    "val_size = full_dataset.length - train_size\n",
    "\n",
    "train_subset, val_subset = random_split(\n",
    "    full_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(69),\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "unfreeze_schedule = {\n",
    "    5: \"audio_last\",  # after 2 epochs - unfreeze last layers of audio encoder\n",
    "    5: \"visual_last\",  # same as above for visual\n",
    "    10: \"all\",  # unfreeze everything\n",
    "}\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    [\n",
    "        {\"params\": fusion_model.fusion_linear.parameters()},\n",
    "        {\"params\": fusion_model.bn.parameters()},\n",
    "        {\"params\": fusion_model.fusion_embedding.parameters()},\n",
    "        {\"params\": fusion_model.classifier.parameters()},\n",
    "    ],\n",
    "    lr=0.001,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "criterion = DiarizationLoss(triplet_lambda=0.3, bce_lambda=0.7)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.8)\n",
    "\n",
    "trained_model, best_val_loss = train_fusion_model(\n",
    "    fusion_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    scheduler,\n",
    "    DEVICE,\n",
    "    num_epochs=100,\n",
    "    unfreeze_schedule=unfreeze_schedule,\n",
    "    checkpoint_dir=\"multimodal_concat_512_checkpoints\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a474f0f-ba17-4fcf-a111-797d6151d1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4791c6-c3d5-4549-867b-f27fbb5341c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
