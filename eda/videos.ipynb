{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import VideoReader\n",
    "from pathlib import Path\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video': {'fps': [25.0], 'duration': [112.52]}, 'audio': {'framerate': [44100.0], 'duration': [112.52399092970522]}}\n",
      "dict_keys(['data', 'pts'])\n"
     ]
    }
   ],
   "source": [
    "video_filename = '../data/msdwild_boundingbox_labels/02904.mp4'\n",
    "stream_type = 'video'\n",
    "stream = VideoReader(video_filename, stream_type)\n",
    "print(stream.get_metadata())\n",
    "result = next(iter(stream))\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[183, 183, 183,  ..., 153, 153, 153],\n",
      "         [183, 183, 184,  ..., 153, 153, 153],\n",
      "         [183, 183, 184,  ..., 153, 153, 153],\n",
      "         ...,\n",
      "         [138, 138, 138,  ...,  90,  89,  89],\n",
      "         [137, 137, 137,  ...,  89,  89,  89],\n",
      "         [137, 137, 137,  ...,  89,  89,  89]],\n",
      "\n",
      "        [[183, 183, 183,  ..., 156, 156, 156],\n",
      "         [183, 183, 184,  ..., 156, 156, 156],\n",
      "         [183, 183, 184,  ..., 156, 156, 156],\n",
      "         ...,\n",
      "         [ 95,  95,  95,  ...,  50,  49,  49],\n",
      "         [ 94,  94,  94,  ...,  49,  49,  49],\n",
      "         [ 94,  94,  94,  ...,  49,  49,  49]],\n",
      "\n",
      "        [[142, 142, 142,  ..., 132, 132, 132],\n",
      "         [142, 142, 143,  ..., 132, 132, 132],\n",
      "         [142, 142, 143,  ..., 132, 132, 132],\n",
      "         ...,\n",
      "         [ 50,  50,  50,  ...,  27,  26,  26],\n",
      "         [ 49,  49,  49,  ...,  26,  26,  26],\n",
      "         [ 49,  49,  49,  ...,  26,  26,  26]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(result['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(result['pts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 720, 1280])\n",
      "torch.Size([3, 720, 1280])\n",
      "torch.Size([3, 720, 1280])\n",
      "torch.Size([3, 720, 1280])\n",
      "torch.Size([3, 720, 1280])\n"
     ]
    }
   ],
   "source": [
    "stream.set_current_stream(\"video\")\n",
    "for frame in itertools.islice(stream, 5) :\n",
    "   print(frame['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 2])\n",
      "torch.Size([1024, 2])\n",
      "torch.Size([1024, 2])\n",
      "torch.Size([1024, 2])\n",
      "torch.Size([1024, 2])\n"
     ]
    }
   ],
   "source": [
    "stream.set_current_stream(\"audio\")\n",
    "for frame in itertools.islice(stream, 5) :\n",
    "   print(frame['data'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
